
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <title>Khayal Abbas Akhar </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Anna Maria Feit">
    <!-- icon of page -->
    <link rel="shortcut icon" href="img/amf.ico">
    <!-- Your styles -->
    <link href="css/style.css" rel="stylesheet" media="screen">
    <!-- Skins -->
    <link href="css/skins/black/black.css" rel="stylesheet" media="screen" class="skin">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->
    <!-- Skins Changer-->
    <!--<script type="text/javascript" src="http://www.google.com/jsapi"></script>-->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-73569014-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-73569014-3');
    </script>
  </head>
  <body>
    <!-- Logo -->
    <header class="logo animated fadeInDown delay1" id="about">
      <div class="container">
        <div class="row-fluid">
          <div class="title_logo">
            <h1>Khayal Abbas Akhtar<small> Site under construction</small></h1>
          </div>
        </div>
      </div>
    </header>
    <!-- End Logo -->
    <!-- Nav-->
    <nav class="nav animated fadeInUp delay1">
      <div class="container">
        <div class="row-fluid">
          <ul id="menu">
            <li><a href="#about">ABOUT ME</a></li>
			<li><a href="#press">Teaching </a></li>            
            <li><a href="#projects">PROJECTS</a></li>
            <li><a href="#publications"</a></li>                  <li><a href="#students"></a></li>
            <li><a href="#contact">CONTACT</a></li>
            <li><a href="">CV <i class="fa fa-download" style="color:#444444;"></i> </a></li>
			<li><a target="_blank"  href="" class="tooltip_hover" title="Twitter profile"> 
				<i class="icon-twitter"></i>
				</a>
			  </li>
			  <li><a target="_blank"  href="" class="tooltip_hover" title="Linkedin profile">
				 <i class="icon-linkedin"></i>  
				</a>                    
			  </li>
			  <li><a target="_blank"  href="" title="Google Scholar profile">
				 <i class="fa fa-graduation-cap"></i>  
				</a>
			  </li>
          </ul>
        </div>
      </div>
    </nav>
    <!-- End Nav-->
	
    <!-- Info Area - about-->
	<section class="info_area" id="about">		
		<div class="container">
		<div class="row-fluid">
		  <div class="span3 me"> <img src="img/crop1.jpg" alt="Khayal Abbas Akhtar">
			  			
				<div class="item_info ">
				<h4>Email:</h4>				 	
				<p>khayalabbas@iqraisb.edu.pk</p>
                                <p>khayalabbas1@gmail.com</p>
				 
				</div>				  
				
		  </div>
		  
			<div class="title_section">
				<h1>ABOUT ME <span class="arrow_title"></span> </h1>
			</div>	
			
			<div class="span8"> 
			<p>I am Khayal Abbas Akhtar , Currently i am a Visiting Faculty - Lab Engineer at Department of Computing & Teachnology, Iqra University, Islamabad Pakistan.. <p/>
			<p><p/>
                                               
                         <p> Previously, I spent few amazing years as an student at Universtiy of Zilina , Slovakia and Iqra Universtiy Islamabad where I majored in Software Engineering.<p/>
		     <p> I am Teaching lab of course "Data Structures and Algorithms, Spring 2021" <p/>	
			<ul class="social">  
			</ul>
			<br>
			<h2> My Research <span class="arrow_title"></span> </h2>
				My research interests are in the area of <a target="_blank" href="http://computationalinteraction.org/">computational interaction</a>. I use methods of optimization, machine learning, and mathematical modeling to understand and improve our interaction with computers. Among other forms of input, I am particularly interested in text input methods and have conducted several studies to understand how people type, in <a target="_blank"  href="https://userinterfaces.aalto.fi/how-we-type">small lab settings</a> and through <a target="_blank"  href="https://userinterfaces.aalto.fi/136Mkeystrokes/">large-scale online typing tests.</a></p>
			</div>

		</div>		
		</div>
		    
	</section>
	 
	 <section class="info_area" id="press">  
		<div class="container">		
		<div class="title_section"> 
			
		</div> 
		<div class="row-fluid">
		<div class="span10">		
		
	   </div>
	   </div>
	   </div>
	</section>
	 
	 <section class="info_area" id="press">  
		<div class="container">		
		<div class="title_section"> 
			<h1>IN THE PRESS<span class="arrow_title"></span> </h1> 
		</div> 
		<div class="row-fluid">
		<div class="span10">		
		<h4> Current <span class="arrow_title"></span> </h2>
		<ul class="fa-ul">
		<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Summer 2021 </strong> <br>
			<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
			
			li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
			<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
		   </ul>
		<h4> My Research <span class="arrow_title"></span> </h2>
			<ul class="fa-ul">
		<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Summer 2021 </strong> <br>
			<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
			
			li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
			<li><i class="fa-li fa fa-caret-right"></i><strong> Data Structures and Algorithms, Spring 2021 </strong> <br>
		   </ul>
	   </div>
	   </div>
	   </div>

	</div>
    <!-- End Section Area - about-->
 
    
      
    <!--  Projects  -->
    <section class="info_area" id="projects">
      <div class="container">
        <div class="title_section">
          <h1>SELECTED PROJECTS <span class="arrow_title"></span> </h1>
        </div> 
        <div class="row-fluid"> 
				  		 
		  </div>
		  <div class="row-fluid">
		  <!-- Item Eye tracking quality-->
          <div class="span2">
            <div class="item-preview"> <img src="img/eye_tracking.jpg" alt="Eye tracking quality">
              <div class="img-preview" onclick="window.open('https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/everyday_eyetracking-1.pdf','_blank');">
                <h3>Eye tracking quality</h3>
                <!--<p>Eye tracking quality can vary a lot in practical scenarios. We analyze the extent of this variation, optimize filter parameters and 
				give recommendations for the design of adaptive gaze-enabled applications. 
                </p>-->
                <a target="_blank"  href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/everyday_eyetracking-1.pdf">See more</a>
              </div>
            </div>
          </div>
          <!-- End Eye tracking quality-->
          
          
            
        </div>
		<div class="title_section">
		<h4>Datasets <span class="arrow_title"></span> </h4>
        </div> 
		<div class="row-fluid"> 
			<div class="span7">
				<div class="accordion-trigger"><i>How We Type</i> Dataset</div>
				<div class="accordion-container">
				<div style="text-align: left;">
				<p>We released the data collected during the How We Type study. The dataset is very large. It contains the motion capture data (movement of hands and fingers during typing), the keystrokes, reference videos, and eye tracking data. The smaller parts of the dataset can be directly downloaded on the <a target="_blank"  href="https://userinterfaces.aalto.fi/how-we-type"><i class="fa fa-arrow-right"></i>project page</a>. Please contact me if you want other parts. 
				</p></div>
				</div>
			
			
				<div class="accordion-trigger"><i>136M Keystrokes</i> Dataset</div>
				<div class="accordion-container"><div style="text-align: left;">
				<p>We collected typing data of over 160,000 computer users participating in an online typing test. This dataset is available on the <a target="_blank"  href="https://userinterfaces.aalto.fi/136Mkeystrokes/"><i class="fa fa-arrow-right"></i>project page</a>. It contains the keypress and -release events with details of each keystroke. 
				</p></div>
				</div>
				
				
				<div class="accordion-trigger"><i>37K Mobile Typists</i> Dataset</div>
				<div class="accordion-container">
				<div style="text-align: left;">
				<p>Data from over 37,000 mobile users completing a 15-sentence typing test on their mobile device. More info on the <a href="https://userinterfaces.aalto.fi/typing37k/"> <i class="fa fa-arrow-right"></i>project page. </a>
				</p></div>
				</div>
			
			</div>
			
		</div>
		
		<div class="title_section">	<h4>Code and Resources <span class="arrow_title"></span> </h4> </div> 
		<div class="row-fluid"> 
			<div class="span7">
				<div class="accordion-trigger">Automatic Labeling of Motion Capture Markers (for Hand tracking)</div>
				<div class="accordion-container"><div style="text-align: left;">
				<p>As part of the <a target="_blank"  href="https://userinterfaces.aalto.fi/how-we-type">How We Type </a> project I developed Python scripts to automatically label motion capture markers based on a nearest 
				neighbor approach. The scripts are free to use and can be found on <a target="_blank"  href="https://github.com/annafeit/motion-capture-labeling"><i class="fa fa-github"></i> GitHub</a>
				</p></div>
				</div>
			</div>
			
		</div>
        <br>
      </div>
    </section>
    <!-- End Projects -->
  

        <!--  Publication  -->
    <section class="info_area" id="publications">
      <div class="container">
        <div class="title_section">
          <h1>PUBLICATIONS AND TALKS <span class="arrow_title"></span> </h1>
        </div>
		
        <div class="row-fluid">		
          <div class="span10">
		  <div class="title_section">
          <h4>Dissertation <span class="arrow_title"></span> </h4>
		 </div> 
		 <div class="accordion-trigger"><i class="fa fa-trophy" style="margin-left:0px; color:#333333;"></i> Assignment Problems for Optimizing Text Input
		  <span><br>
                	Aalto University publication series DOCTORAL DISSERTATIONS, 103/2018 </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">               
			  
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="http://urn.fi/URN:ISBN:978-952-60-8016-1">Dissertation</a>    
					
                <a target="_blank"  href="http://annafeit.de/resources/papers/Dissertation_cite.txt">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>					
                </div>				
				<div class="row-fluid">
				<br>
              <a href="http://urn.fi/URN:ISBN:978-952-60-8016-1">
                   <div class="span2"><img src="https://aaltodoc.aalto.fi/bitstream/handle/123456789/31312/isbn9789526080161.png?sequence=2&isAllowed=y" alt="Annas dissertation"></div></a>				   				   
				   <div class="span8">
				   <p><i>This thesis won the <a  href="https://sigchi.org/awards/sigchi-award-recipients/2019-sigchi-awards/">SIGCHI Outstanding Dissertation Award</a> in 2019. </i></p>
				   <p>My PhD thesis advances the state of the art in text-entry optimization by proposing novel objective functions that quantify the performance, ergonomics and learnability of a text input method. In addition, the thesis gives an introduction to user interface optimization and summarizes work in text entry optimization from the last 80 years. The assignment problem thereby serves as a unifying framework for formulating the novel objectives as well as those from prior work. I show the optimization of text input in three concrete cases: text input with multi-finger gestures in mid-air, text input on a long piano keyboard, and -- for a contribution to the official French keyboard standard -- input of special characters via a physical keyboard. 
			  While the work focused on text input, the assignment problem can be used to model other design problems in HCI (e.g., how best to assign commands to UI controls or distribute UI elements across several devices), for which the same problem formulations, optimization techniques, and even models could be applied.</p></div></div>
            </div>
		 
		 
		  <div class="title_section">
          <h4>Full papers <span class="arrow_title"></span> </h4>
		 </div> 
		 
		 <div class="accordion-trigger"> Detecting Relevance during Decision-Making from Eye Movements for UI Adaptation
		  <span><br>
               Conference paper, ACM ETRA 2020. </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">               
			  <span style="font-weight: bold;">
				<a target="_blank"  href=" https://dl.acm.org/doi/10.1145/3379155.3391321?cid=81556550256">                                  
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF  </a></span>
                <a target="_blank"  href="resources/papers/etra20_cite.txt">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>
					
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="https://ait.ethz.ch/projects/2020/relevance-detection/">Project page</a>     
                <span style="font-style: italic;">
				<br><br>
					<span style="font-weight:bold;">
					Anna Maria Feit, Lukas Vordemann, Seonwook Park, Catharina Berube, Otmar Hilliges
					</span>
                </span>
                </div>
              <p>This paper proposes an approach to detect information relevance during decision-making from eye movements in order to enable user interface adaptation. This is a challenging task because gaze behavior varies greatly across individual users and tasks and ground-truth data is difficult to obtain. Thus, prior work has mostly focused on simpler target-search tasks or on establishing general interest, where gaze behavior is less complex. From the literature, we identify six metrics that capture different aspects of the gaze behavior during decision-making and combine them in a voting scheme. We empirically show, that this accounts for the large variations in gaze behavior and out-performs standalone metrics. Importantly, it offers an intuitive way to control the amount of detected information, which is crucial for different UI adaptation schemes to succeed. We show the applicability of our approach by developing a room-search application that changes the visual saliency of content detected as relevant. In an empirical study, we show that it detects up to 97% of relevant elements with respect to user self-reporting, which allows us to meaningfully adapt the interface, as confirmed by participants. Our approach is fast, does not need any explicit user input and can be applied independent of task and user.
			</p>
            </div>
		 
		 <div class="accordion-trigger"> Context-Aware Online Adaption of Mixed Reality Interfaces
		  <span><br>
               Conference paper, ACM UIST 2019. </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">               
			  <span style="font-weight: bold;">
				<a target="_blank"  href="https://ait.ethz.ch/projects/2019/computationalMR/downloads/computationalMR_preprint.pdf">                                  
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF  </a></span>
                <a target="_blank"  href="https://ait.ethz.ch/projects/2019/computationalMR/lindlbauer2019.bib">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>
					
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="https://ait.ethz.ch/projects/2019/computationalMR/">Project page</a>     
					
				<!--<a target="_blank"  href="https://www.slideshare.net/oulasvir/observations-on-typing-from-136-million-keystrokes-presentation-by-antti-oulasvirta-at-chi2018-april-2018-montreal">
                  <span style="font-weight: bold;">
                    <i class="fa fa-slideshare" style="color:#333333; margin-left:20px;"></i>
                    Slides </span> </a>-->
					
                <span style="font-style: italic;">
				<br><br>
					<span style="font-weight:bold;">
					David Lindlbauer, Anna Maria Feit, Otmar Hilliges
					</span>
                </span>
                </div>
              <p>We present an optimization-based approach for Mixed Reality (MR) systems to automatically control when and where applications are shown, and how much information they display. Currently, content creators design applications, and users then manually adjust which applications are visible and how much information they show. This choice has to be adjusted every time users switch context, i.e., whenever they switch their task or environment. Since context switches happen many times a day, we believe that MR interfaces require automation to alleviate this problem. We propose a real-time approach to automate this process based on users' current cognitive load and knowledge about their task and environment. Our system adapts which applications are displayed, how much information they show, and where they are placed. We formulate this problem as a mix of rule-based decision making and combinatorial optimization which can be solved efficiently in real-time. We present a set of proof-of-concept applications showing that our approach is applicable in a wide range of scenarios. Finally, we present an evaluation with a dual task paradigm. Our approach resulted in similar task performance as a traditional UI and decreased secondary tasks interactions by 36%.
			</p>
            </div>
			
		 <div class="accordion-trigger"> <img src="img/hm.png" alt="Honorable Mention Award" height="20" width="20">How do People Type on Mobile Devices? Observations from a Study with 37,000 Volunteers
		  <span><br>
               Conference paper, ACM MobileHCI 2019. </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">               
			  <span style="font-weight: bold;">				
                <a target="_blank"  href="https://userinterfaces.aalto.fi/typing37k/resources/Mobile_typing_study.pdf">                                  
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF  </a></span>
                <a target="_blank"  href="http://annafeit.de/resources/papers/typing37k_MobileHCI19_cite.txt">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>
					
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="https://userinterfaces.aalto.fi/typing37k/">Project page</a>     
					
				<a target="_blank"  href="https://www.slideshare.net/kimsunjun5/how-do-people-type-on-mobile-devices-observations-from-a-study-with-37000-volunteers-mobilehci-2019">
                  <span style="font-weight: bold;">
                    <i class="fa fa-slideshare" style="color:#333333; margin-left:20px;"></i>
                    Slides </span> </a>
					
				
					
                <span style="font-style: italic;">
				<br><br>
					<span style="font-weight:bold;">
					Kseniia Palin, Anna Maria Feit, Sunjun Kim, Per Ola Kristensson, Antti Oulasvirta
					</span>
                </span>
                </div>
              <p>This paper presents a large-scale dataset on mobile text entry collected via a web-based transcription task performed by 37,370 volunteers. The average typing speed was 36.2 WPM with 2.3 uncorrected errors.
			The scale of the data enables powerful statistical analyses on the correlation between typing performance and various factors, such as demographics, finger usage, and use of intelligent text entry techniques. 
			We report effects of age and finger usage on performance that correspond to previous studies.
			We also find evidence of relationships between performance and use of intelligent text entry techniques:
			auto-correct usage correlates positively with entry rates, whereas word prediction usage has a negative correlation.
			To aid further work on modeling, machine learning and design improvements in mobile text entry, we make the code and dataset openly available.
			</p>
            </div>
		 
		 <div class="accordion-trigger"> <img src="img/hm.png" alt="Honorable Mention Award" height="20" width="20">Observations on Typing from 136 Million Keystrokes
		  <span><br>
                Conference paper, ACM CHI 2018. Honourable Mention Award. </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">               
			  
                <a target="_blank"  href="http://userinterfaces.aalto.fi/136Mkeystrokes/resources/chi-18-analysis.pdf">                  
                <span style="font-weight: bold;">
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF, 2.8MB </span> </a>
                <a target="_blank"  href="http://annafeit.de/resources/papers/136Mkeystrokes_CHI18_cite.txt">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>
					
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="http://userinterfaces.aalto.fi/136Mkeystrokes/">Project page</a>     
					
				<a target="_blank"  href="https://www.slideshare.net/oulasvir/observations-on-typing-from-136-million-keystrokes-presentation-by-antti-oulasvirta-at-chi2018-april-2018-montreal">
                  <span style="font-weight: bold;">
                    <i class="fa fa-slideshare" style="color:#333333; margin-left:20px;"></i>
                    Slides </span> </a>
					
                <span style="font-style: italic;">
				<br><br>
					<span style="font-weight:bold;">
					Vivek Dhakal, Anna Maria Feit, Per Ola Kristensson, Antti Oulasvirta
					</span>
                </span>
              </div>
              <p>We report on typing behaviour and performance of 168,000 volunteers in an online study. The large dataset allows detailed statistical analyses of keystroking patterns, linking them to typing performance. Besides reporting distributions and confirming some earlier findings, we report two new findings. First, letter pairs that are typed by different hands or fingers are more predictive of typing speed than, for example, letter repetitions. Second, rollover-typing, wherein the next key is pressed before the previous one is released, is sur- prisingly prevalent. Notwithstanding considerable variation in typing patterns, unsupervised clustering using normalised inter-key intervals reveals that most users can be divided into eight groups of typists that differ in performance, accuracy, hand and finger usage, and rollover. The code and dataset are released for scientific use.</p>
            </div>
			
		<div class="accordion-trigger"> AdaM: Adapting Multi-User Interfaces for Collaborative Environments in Real-Time
		  <span><br>
                Conference paper, ACM CHI 2018. </span></div>
            <div class="accordion-container">
				<div style="text-align: left;">     
				<a target="_blank"  href="https://ait.ethz.ch/projects/2018/adam/downloads/park2018chi.pdf">                  
                <span style="font-weight: bold;">
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF, 4MB </span> </a>
                <a target="_blank"  href="https://ait.ethz.ch/projects/2018/adam/park2018chi.bib">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>					                
                
                <i class="fa fa-arrow-right" style="margin-left:20px; color:#333333;"></i>
                <a target="_blank"  style="font-weight: bold;"
                    href="https://ait.ethz.ch/projects/2018/adam/">Project page</a> 			               
				<br><br>
				<span style="font-style: italic;">
					<span style="font-weight:bold;">
					Seonwook Park, Christoph Gebhardt, Roman RÃ¤dle, Anna Maria Feit, Hana Vrzakova, Niraj Dayama, Hui-Shyong Yeo, Clemens Klokmose, Aaron Quigley, Antti Oulasvirta, Otmar Hilliges 
					</span>
                </span>
                </div>
              <p>Developing cross-device multi-user interfaces (UIs) is a challenging problem. There are numerous ways in which content and interactivity can be distributed. However, good solutions must consider multiple users, their roles, their preferences and access rights, as well as device capabilities. Manual and rule-based solutions are tedious to create and do not scale to larger problems nor do they adapt to dynamic changes, such as users leaving or joining an activity. In this paper, we cast the problem of UI distribution as an assignment problem and propose to solve it using combinatorial optimization. We present a mixed integer programming formulation which allows real-time applications in dynamically changing collaborative settings. It optimizes the allocation of UI elements based on device capabilities, user roles, preferences, and access rights. We present a proof-of-concept designer-in-the-loop tool, allowing for quick solution exploration. Finally, we compare our approach to traditional paper prototyping in a lab study.</p>
            </div>
			
		<div class="accordion-trigger"> Physical Keyboards in Virtual Reality: Analysis of Typing Performance and Effects of Avatar Hands
		  <span><br>
                Conference paper, ACM CHI 2018. </span></div>
            <div class="accordion-container">
              <div style="text-align: left;">     
			   <span style="font-style: italic;">				
				<a target="_blank"  href="http://annafeit.de/resources/papers/Physical_keyboards_in_VR_CHI18.pdf">                  
                <span style="font-weight: bold;">
                  <i class="fa fa-file-pdf-o"></i> 
                  PDF, 8.2MB </span> </a>
                <a target="_blank"  href="http://annafeit.de/resources/papers/Physical_keyboards_in_VR_CHI18_cite.txt">
                  <span style="font-weight: bold;">
                    <i class="fa fa-quote-right" style="color:#333333; margin-left:20px;"></i>
                    BibTeX </span> </a>					                
                				
               <br> <br>
               
					<span style="font-weight:bold;">
					Pascal Knierim, Valentin Schwind, Anna Maria Feit, Florian Nieuwenhuizen, Niels Henze
					</span>
                </span>
                </div>
              <p>Entering text is one of the most common tasks when interacting with computing systems. Virtual Reality (VR) presents a challenge as neither the user's hands nor the physical input devices are directly visible. Hence, conventional desktop peripherals are very slow, imprecise, and cumbersome. We developed a apparatus that tracks the user's hands, and a physical keyboard, and visualize them in VR. In a text input study with 32 participants, we investigated the achievable text entry speed and the effect of hand representations and transparency on typing performance, workload, and presence. With our {apparatus}, experienced typists benefited from seeing their hands, and reach almost outside-VR performance. Inexperienced typists profited from semi-transparent hands, which enabled them to type just 5.6 WPM slower than with a regular desktop setup. We conclude that optimizing the visualization of hands in V
